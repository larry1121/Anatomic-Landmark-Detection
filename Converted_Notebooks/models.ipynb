{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1aa88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "# (16, 11) for 600; (10, 8) for 300; (37, 30) for 1000\n",
    "import lossFunction\n",
    "import utils\n",
    "\n",
    "class dilationInceptionModule(nn.Module):\n",
    "\tdef __init__(self , inplanes, planes):\n",
    "\t\tsuper(dilationInceptionModule, self).__init__()\n",
    "\n",
    "\t\tfnum = int(planes / 4)\n",
    "\t\tself.temConv1 = nn.Sequential(\n",
    "\t\t\t\tnn.Conv2d(inplanes, fnum, kernel_size=(1, 1), stride=1, padding = 0),\n",
    "\t\t\t\tnn.BatchNorm2d(fnum, track_running_stats=False),\n",
    "\t\t\t\tnn.ReLU(inplace = True),\n",
    "\t\t)\n",
    "\t\tself.temConv2 = nn.Sequential(\n",
    "\t\t\t\tnn.Conv2d(inplanes, fnum, kernel_size=(3, 3), stride=1, padding = 1),\n",
    "\t\t\t\tnn.BatchNorm2d(fnum, track_running_stats=False),\n",
    "\t\t\t\tnn.ReLU(inplace = True),\n",
    "\t\t)\n",
    "\t\tself.temConv3 = nn.Sequential(\n",
    "\t\t\t\tnn.Conv2d(inplanes, fnum, kernel_size=(3, 3), stride=1, padding = 2, dilation = 2),\n",
    "\t\t\t\tnn.BatchNorm2d(fnum, track_running_stats=False),\n",
    "\t\t\t\tnn.ReLU(inplace = True),\n",
    "\t\t)\n",
    "\t\tself.temConv4 = nn.Sequential(\n",
    "\t\t\t\tnn.Conv2d(inplanes, fnum, kernel_size=(3, 3), stride=1, padding = 4, dilation = 4),\n",
    "\t\t\t\tnn.BatchNorm2d(fnum, track_running_stats=False),\n",
    "\t\t\t\tnn.ReLU(inplace = True),\n",
    "\t\t)\n",
    "\t\tself.conv = nn.Conv2d(4, 1, kernel_size=(1, 1), stride=1, padding = 0)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx1 = self.temConv1(x)\n",
    "\t\tx2 = self.temConv2(x)\n",
    "\t\tx3 = self.temConv3(x)\n",
    "\t\tx4 = self.temConv4(x)\n",
    "\t\ty = torch.cat((x1, x2, x3, x4), 1)\n",
    "\t\treturn y\n",
    "\n",
    "class fusionResNet50(nn.Module):\n",
    "\tdef __init__(self , model, batchSize, landmarksNum, useGPU, image_scale, R):\n",
    "\t\tsuper(fusionResNet50, self).__init__()\n",
    "\n",
    "\n",
    "\t\tpara_list = list(model.children())\n",
    "\t\tself.relu = nn.ReLU(inplace = True)\n",
    "\t\tself.resnet_layer1 = nn.Sequential(*para_list[:5])\n",
    "\t\tself.resnet_layer2 = para_list[5]\n",
    "\t\tself.resnet_layer3 = para_list[6]\n",
    "\t\tself.resnet_layer4 = para_list[7]\n",
    "\n",
    "\t\tfnum = 96\n",
    "\t\tself.fnum = fnum\n",
    "\t\tself.f_conv4 = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(2048, fnum, kernel_size=(1, 1), stride=1, padding = 0 ),\n",
    "\t\t\tnn.BatchNorm2d(fnum,track_running_stats=False),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t)\n",
    "\n",
    "\t\tself.f_conv3 = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(1024, fnum, kernel_size=(1, 1), stride=1, padding = 0 ),\n",
    "\t\t\tnn.BatchNorm2d(fnum,track_running_stats=False),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t)\n",
    "\n",
    "\t\tself.f_conv2 = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(512, fnum, kernel_size=(1, 1), stride=1, padding = 0 ),\n",
    "\t\t\tnn.BatchNorm2d(fnum,track_running_stats=False),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t)\n",
    "\n",
    "\t\tself.f_conv1 = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(256, fnum, kernel_size=(1, 1), stride=1, padding = 0 ),\n",
    "\t\t\tnn.BatchNorm2d(fnum,track_running_stats=False),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t)\n",
    "\n",
    "\t\tself.avgPool8t = nn.AvgPool2d(8, 8)\n",
    "\t\tself.avgPool4t = nn.AvgPool2d(4, 4)\n",
    "\t\tself.avgPool2t = nn.AvgPool2d(2, 2)\n",
    "\t\tself.attentionLayer1 = nn.Sequential(\n",
    "\t\t\tnn.Linear(500, 128, bias = False),\n",
    "\t\t\tnn.BatchNorm1d(1,track_running_stats=False),\n",
    "\t\t\tnn.Tanh(),\n",
    "\t\t\tnn.Linear(128, landmarksNum*3, bias = False),\n",
    "\t\t\t#~ nn.BatchNorm1d(1,track_running_stats=False),\n",
    "\t\t\tnn.Softmax(dim = 0)\n",
    "\t\t)\n",
    "\n",
    "\t\tmoduleList = []\n",
    "\t\tfor i in range(landmarksNum*3):\n",
    "\t\t\t#~ temConv = dilationInceptionModule(fnum*4, 1)\n",
    "\t\t\ttemConv = nn.Conv2d(fnum*4, 1, kernel_size=(1, 1), stride=1, padding = 0)\n",
    "\t\t\tmoduleList.append(temConv)\n",
    "\n",
    "\t\tself.moduleList = nn.ModuleList(moduleList)\n",
    "\n",
    "\t\tscaleFactorList = []\n",
    "\t\tfor i in range(landmarksNum*3):\n",
    "\t\t\tscaleFactorList.append(nn.Linear(1, 1, bias = False))\n",
    "\t\tself.scaleFactorList = nn.ModuleList(scaleFactorList)\n",
    "\n",
    "\t\tself.inception = dilationInceptionModule(fnum*4, fnum*4)\n",
    "\t\tself.prediction = nn.Conv2d(2048, landmarksNum*3, kernel_size=(1, 1), stride=1, padding = 0 )\n",
    "\t\tself.Upsample2 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "\t\tself.Upsample4 = nn.Upsample(scale_factor=4, mode='bilinear')\n",
    "\t\tself.Upsample8 = nn.Upsample(scale_factor=8, mode='bilinear')\n",
    "\t\tself.Upsample16 = nn.Upsample(scale_factor=16, mode='bilinear')\n",
    "\t\tself.Upsample32 = nn.Upsample(scale_factor=32, mode='bilinear')\n",
    "\n",
    "\t\tself.landmarksNum = landmarksNum\n",
    "\t\tself.batchSize = batchSize\n",
    "\t\tself.useGPU = useGPU\n",
    "\t\tself.R2 = R\n",
    "\n",
    "\tdef getCoordinate(self, outputs1):\n",
    "\t\theatmaps = F.sigmoid(outputs1[:, 0:self.landmarksNum, :, :])\n",
    "\t\theatmap_sum = torch.sum(heatmaps.view(self.batchSize, self.landmarksNum, -1), dim=2)\n",
    "\n",
    "\t\tXmap1 = heatmaps * self.coordinateX\n",
    "\t\tYmap1 = heatmaps * self.coordinateY\n",
    "\n",
    "\t\tXmean1 = torch.sum(Xmap1.view(self.batchSize, self.landmarksNum, -1), dim=2) / heatmap_sum\n",
    "\t\tYmean1 = torch.sum(Ymap1.view(self.batchSize, self.landmarksNum, -1), dim=2) / heatmap_sum\n",
    "\n",
    "\t\tcoordinateMean1 = torch.stack([Xmean1, Ymean1]).permute(1, 2, 0)\n",
    "\t\tcoordinateMean2 = 0\n",
    "\n",
    "\t\tXDevmap = torch.pow(self.coordinateX - Xmean1.view(self.batchSize, self.landmarksNum, 1, 1), 2)\n",
    "\t\tYDevmap = torch.pow(self.coordinateY - Ymean1.view(self.batchSize, self.landmarksNum, 1, 1), 2)\n",
    "\n",
    "\t\tXDevmap = heatmaps * XDevmap\n",
    "\t\tYDevmap = heatmaps * YDevmap\n",
    "\n",
    "\t\tcoordinateDev = torch.sum((XDevmap + YDevmap).view(self.batchSize, self.landmarksNum, -1), dim=2) / heatmap_sum\n",
    "\n",
    "\t\treturn coordinateMean1, coordinateMean2, coordinateDev\n",
    "\n",
    "\tdef getAttention(self, bone, fnum):\n",
    "\t\tbone = self.avgPool8t(bone).view(fnum, -1)\n",
    "\t\tbone = bone.unsqueeze(1)\n",
    "\t\ty = self.attentionLayer1(bone).squeeze(1).transpose(1, 0)\n",
    "\n",
    "\t\treturn y\n",
    "\n",
    "\tdef predictionWithAttention(self, bone, attentions):\n",
    "\t\tfeatureNum, channelNum = attentions.size()[0], attentions.size()[1]\n",
    "\t\tattentionMaps = []\n",
    "\t\tfor i in range(featureNum):\n",
    "\t\t\tattention = attentions[i, :]\n",
    "\t\t\tattention = attention.view(1, channelNum, 1, 1)\n",
    "\t\t\tattentionMap = attention * bone * channelNum\n",
    "\t\t\tattentionMaps.append(self.moduleList[i](attentionMap))\n",
    "\t\tattentionMaps = torch.stack(attentionMaps).squeeze().unsqueeze(0)\n",
    "\t\treturn attentionMaps\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.resnet_layer1(x)\n",
    "\t\tf1 = self.f_conv1(x)\n",
    "\t\t#~ print(x.size())\n",
    "\t\tx = self.resnet_layer2(x)\n",
    "\t\tf2 = self.f_conv2(x)\n",
    "\t\t#~ print(x.size())\n",
    "\t\tx = self.resnet_layer3(x)\n",
    "\t\tf3 = self.f_conv3(x)\n",
    "\t\t#~ print(x.size())\n",
    "\t\tx = self.resnet_layer4(x)\n",
    "\t\tf4 = self.f_conv4(x)\n",
    "\n",
    "\t\tf2 = self.Upsample2(f2)\n",
    "\t\tf3 = self.Upsample4(f3)\n",
    "\t\tf4 = self.Upsample8(f4)\n",
    "\n",
    "\t\tbone = torch.cat((f1, f2, f3, f4), 1)\n",
    "\t\tbone = self.inception(bone)\n",
    "\t\tattention = self.getAttention(bone, self.fnum*4)\n",
    "\n",
    "\t\ty = self.Upsample4(self.predictionWithAttention(bone, attention))\n",
    "\t\tcoordinateMean1, coordinateMean2 = 0, 0\n",
    "\n",
    "\t\treturn [y], coordinateMean1, coordinateMean2\n",
    "\n",
    "class fusionVGG19(nn.Module):\n",
    "\tdef __init__(self , model, config):\n",
    "\t\tsuper(fusionVGG19, self).__init__()\n",
    "\t\tpara_list = list(model.children())[0]\n",
    "\n",
    "\t\tself.VGG_layer1 = nn.Sequential(*para_list[:14])\n",
    "\t\tself.VGG_layer2 = nn.Sequential(*para_list[14:27])\n",
    "\t\tself.VGG_layer3 = nn.Sequential(*para_list[27:40])\n",
    "\t\tself.VGG_layer4 = nn.Sequential(*para_list[40:])\n",
    "\t\tself.relu = nn.ReLU(inplace = True)\n",
    "\t\t\n",
    "\t\tfnum = 64\n",
    "\t\tself.fnum = fnum\n",
    "\t\tself.f_conv4 = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(512, fnum, kernel_size=(1, 1), stride=1, padding = 0 ),\n",
    "\t\t\tnn.BatchNorm2d(fnum,track_running_stats=False),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tself.f_conv3 = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(512, fnum, kernel_size=(1, 1), stride=1, padding = 0 ),\n",
    "\t\t\tnn.BatchNorm2d(fnum,track_running_stats=False),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tself.f_conv2 = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(256, fnum, kernel_size=(1, 1), stride=1, padding = 0 ),\n",
    "\t\t\tnn.BatchNorm2d(fnum,track_running_stats=False),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tself.f_conv1 = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(128, fnum, kernel_size=(1, 1), stride=1, padding = 0 ),\n",
    "\t\t\tnn.BatchNorm2d(fnum,track_running_stats=False),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tself.avgPool8t = nn.AvgPool2d(8, 8)\n",
    "\t\tself.avgPool4t = nn.AvgPool2d(4, 4)\n",
    "\t\tself.avgPool2t = nn.AvgPool2d(2, 2)\n",
    "\t\tself.attentionLayer1 = nn.Sequential(\n",
    "\t\t\tnn.Linear(500, 128, bias = False),\n",
    "\t\t\tnn.BatchNorm1d(1,track_running_stats=False),\n",
    "\t\t\tnn.Tanh(),\n",
    "\t\t\tnn.Linear(128, config.landmarkNum*3, bias = False),\n",
    "\t\t\tnn.Softmax(dim = 0)\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tmoduleList = []\n",
    "\t\tfor i in range(config.landmarkNum*3):\n",
    "\t\t\ttemConv = nn.Conv2d(fnum*4, 1, kernel_size=(1, 1), stride=1, padding = 0)\n",
    "\t\t\tmoduleList.append(temConv)\n",
    "\t\t\t\n",
    "\t\tself.moduleList = nn.ModuleList(moduleList)\n",
    "\t\tself.dilated_block = dilationInceptionModule(fnum*4, fnum*4)\n",
    "\t\tself.prediction = nn.Conv2d(fnum*4, config.landmarkNum*3, kernel_size=(1, 1), stride=1, padding = 0)\n",
    "\t\tself.Upsample2 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "\t\tself.Upsample4 = nn.Upsample(scale_factor=4, mode='bilinear')\n",
    "\t\tself.Upsample8 = nn.Upsample(scale_factor=8, mode='bilinear')\n",
    "\t\tself.Upsample16 = nn.Upsample(scale_factor=16, mode='bilinear')\n",
    "\t\tself.Upsample32 = nn.Upsample(scale_factor=32, mode='bilinear')\n",
    "\t\t\n",
    "\t\tself.landmarksNum = config.landmarkNum\n",
    "\t\tself.batchSize = config.batchSize\n",
    "\t\tself.R2 = config.R2\n",
    "\t\t\n",
    "\t\tself.higth, self.width = config.image_scale\n",
    "\t\t\n",
    "\t\tself.coordinateX = torch.ones(self.batchSize, self.landmarksNum, self.higth, self.width).cuda(config.use_gpu)\n",
    "\t\tself.coordinateY = torch.ones(self.batchSize, self.landmarksNum, self.higth, self.width).cuda(config.use_gpu)\n",
    "\t\t\n",
    "\t\tfor i in range(self.higth):\n",
    "\t\t\tself.coordinateX[:, :, i, :] = self.coordinateX[:, :, i, :] * i\n",
    "\t\t\t\n",
    "\t\tfor i in range(self.width):\n",
    "\t\t\tself.coordinateY[:, :, :, i] = self.coordinateY[:, :, :, i] * i\n",
    "\n",
    "\t\tself.coordinateX, self.coordinateY = self.coordinateX / (self.higth - 1), self.coordinateY / (self.width - 1)\n",
    "\n",
    "\tdef getCoordinate(self, outputs1):\n",
    "\t\theatmaps = F.sigmoid(outputs1[:, 0:self.landmarksNum, :, :])\n",
    "\t\theatmap_sum = torch.sum(heatmaps.view(self.batchSize, self.landmarksNum, -1), dim = 2)\n",
    "\t\t\n",
    "\t\tXmap1 = heatmaps * self.coordinateX\n",
    "\t\tYmap1 = heatmaps * self.coordinateY\n",
    "\t\t\n",
    "\t\tXmean1 = torch.sum(Xmap1.view(self.batchSize, self.landmarksNum, -1), dim = 2) / heatmap_sum\n",
    "\t\tYmean1 = torch.sum(Ymap1.view(self.batchSize, self.landmarksNum, -1), dim = 2) / heatmap_sum\n",
    "\n",
    "\t\tcoordinateMean1 = torch.stack([Xmean1, Ymean1]).permute(1, 2, 0)\n",
    "\t\tcoordinateMean2 = 0\n",
    "\n",
    "\t\tXDevmap = torch.pow(self.coordinateX - Xmean1.view(self.batchSize, self.landmarksNum, 1, 1), 2)\n",
    "\t\tYDevmap = torch.pow(self.coordinateY - Ymean1.view(self.batchSize, self.landmarksNum, 1, 1), 2)\n",
    "\n",
    "\t\tXDevmap = heatmaps * XDevmap\n",
    "\t\tYDevmap = heatmaps * YDevmap\n",
    "\t\t\n",
    "\t\tcoordinateDev = torch.sum((XDevmap + YDevmap).view(self.batchSize, self.landmarksNum, -1), dim = 2) / heatmap_sum\n",
    "\t\t\n",
    "\t\treturn coordinateMean1, coordinateMean2, coordinateDev\n",
    "\n",
    "\tdef getAttention(self, bone, fnum):\n",
    "\t\tbone = self.avgPool8t(bone).view(fnum, -1)\n",
    "\t\tbone = bone.unsqueeze(1)\n",
    "\t\ty = self.attentionLayer1(bone).squeeze(1).transpose(1, 0)\n",
    "\t\treturn y\n",
    "\n",
    "\tdef predictionWithAttention(self, bone, attentions):\n",
    "\t\tfeatureNum, channelNum = attentions.size()[0], attentions.size()[1]\n",
    "\n",
    "\t\tattentionMaps = []\n",
    "\t\tfor i in range(featureNum):\n",
    "\t\t\tattention = attentions[i, :]\n",
    "\t\t\tattention = attention.view(1, channelNum, 1, 1)\n",
    "\t\t\tattentionMap = attention * bone * channelNum\n",
    "\t\t\tattentionMaps.append(self.moduleList[i](attentionMap))\n",
    "\n",
    "\t\tattentionMaps = torch.stack(attentionMaps).squeeze().unsqueeze(0)\n",
    "\t\treturn attentionMaps\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.VGG_layer1(x)\n",
    "\t\tf1 = self.f_conv1(x)\n",
    "\n",
    "\t\tx = self.VGG_layer2(x)\n",
    "\t\tf2 = self.f_conv2(x)\n",
    "\n",
    "\t\tx = self.VGG_layer3(x)\n",
    "\t\tf3 = self.f_conv3(x)\n",
    "\n",
    "\t\tx = self.VGG_layer4(x)\n",
    "\t\tf4 = self.f_conv4(x)\n",
    "\n",
    "\t\tf2 = self.Upsample2(f2)\n",
    "\t\tf3 = self.Upsample4(f3)\n",
    "\t\tf4 = self.Upsample8(f4)\n",
    "\t\tbone = torch.cat((f1, f2, f3, f4), 1)\n",
    "\n",
    "\t\t# Attentive Feature Pyramid Fusion\n",
    "\t\tbone = self.dilated_block(bone)\n",
    "\t\tattention = self.getAttention(bone, self.fnum*4)\n",
    "\t\ty = self.Upsample4(self.predictionWithAttention(bone, attention))\n",
    "\n",
    "\t\t# predicting landmarks with the integral operation\n",
    "\t\t# coordinateMean1, coordinateMean2, coordinateDev = self.getCoordinate(y)\n",
    "\n",
    "\t\treturn [y]\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
