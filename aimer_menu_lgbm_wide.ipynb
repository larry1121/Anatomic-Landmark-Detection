{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/larry1121/Anatomic-Landmark-Detection/blob/main/aimer_menu_lgbm_wide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd6Qwn6F49m8"
      },
      "source": [
        "# LG Aimers (DACON) – 식음업장 메뉴 수요 예측 (Phase2)\n",
        "### Global LightGBM + Recursive 7-day Forecast (Wide Submission)\n",
        "\n",
        "**사용법 요약**\n",
        "1) 아래 1번 셀을 실행해 의존성을 설치합니다. (로컬 환경에서만 필요)\n",
        "2) 2번 셀을 실행해 전체 파이프라인 함수를 로드합니다.\n",
        "3) 3번 셀에서 `data_dir`와 `out_path`를 설정하고 실행하면, `sample_submission.csv`와 동일한 **가로(와이드)** 포맷의 `submission.csv`가 생성됩니다.\n",
        "\n",
        "**데이터 폴더 구조** (예시)\n",
        "```\n",
        "data/\n",
        "  train/train.csv\n",
        "  test/TEST_00.csv ... TEST_09.csv\n",
        "  sample_submission.csv\n",
        "```\n",
        "\n",
        "**룰 준수 사항**\n",
        "- Train: train.csv만 사용\n",
        "- Inference: 각 TEST_xx의 28일 입력만 사용 (샘플 간 독립)\n",
        "- 예측: 재귀 방식(D+1→창 업데이트→…→D+7)\n",
        "- 외부데이터 미사용, 도메인지식(요일/공휴일)만 활용\n",
        "- 음수 매출은 0으로 클립 (정답에 음수 없음)\n"
      ],
      "id": "cd6Qwn6F49m8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqKLA50349m-",
        "outputId": "1d6179e2-e3b1-44a6-f6c2-99b35f8c8c32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "def pip_install(pkg):\n",
        "    try:\n",
        "        __import__(pkg.split('==')[0].split('>')[0].split('<')[0])\n",
        "    except Exception:\n",
        "        !pip install {pkg}\n",
        "\n",
        "for p in ['pandas','numpy','lightgbm','holidays','scikit-learn']:\n",
        "    try:\n",
        "        __import__(p)\n",
        "    except Exception:\n",
        "        pip_install(p)\n"
      ],
      "id": "YqKLA50349m-"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "32LR50BV49m_"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from typing import Tuple, List, Dict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# 공휴일/환경\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "try:\n",
        "    import holidays\n",
        "    KR_HOL = holidays.KR()\n",
        "except Exception:\n",
        "    KR_HOL = None\n",
        "    warnings.warn(\"holidays 패키지 미설치: 공휴일 피처 없이 진행합니다.\")\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# 공통 유틸/피처\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "def split_store_menu(name: str) -> Tuple[str, str]:\n",
        "    if not isinstance(name, str): return (\"\", \"\")\n",
        "    parts = name.split(\"_\", 1)\n",
        "    return (parts[0], parts[1]) if len(parts) == 2 else (name, \"\")\n",
        "\n",
        "def is_holiday_kr(dt: pd.Timestamp) -> int:\n",
        "    if KR_HOL is None: return 0\n",
        "    try:\n",
        "        return int(dt in KR_HOL)\n",
        "    except Exception:\n",
        "        return 0\n",
        "\n",
        "def build_calendar_features(dates: pd.Series) -> pd.DataFrame:\n",
        "    df = pd.DataFrame({\n",
        "        \"dow\": dates.dt.weekday,\n",
        "        \"is_weekend\": dates.dt.weekday.isin([5,6]).astype(int),\n",
        "        \"dom\": dates.dt.day,\n",
        "        \"weekofyear\": dates.dt.isocalendar().week.astype(int),\n",
        "        \"month\": dates.dt.month,\n",
        "        \"doy\": dates.dt.dayofyear,\n",
        "        \"is_month_start\": dates.dt.is_month_start.astype(int),\n",
        "        \"is_month_end\": dates.dt.is_month_end.astype(int),\n",
        "    }, index=dates.index)\n",
        "    df[\"dow_sin\"] = np.sin(2*np.pi*df[\"dow\"]/7)\n",
        "    df[\"dow_cos\"] = np.cos(2*np.pi*df[\"dow\"]/7)\n",
        "    df[\"month_sin\"] = np.sin(2*np.pi*df[\"month\"]/12)\n",
        "    df[\"month_cos\"] = np.cos(2*np.pi*df[\"month\"]/12)\n",
        "    df[\"is_holiday\"] = dates.apply(is_holiday_kr).astype(int) if KR_HOL is not None else 0\n",
        "    return df\n",
        "\n",
        "def make_lag_features(y: pd.Series, max_lag: int = 28) -> pd.DataFrame:\n",
        "    y0 = y.clip(lower=0)\n",
        "    feats = {f\"lag_{k}\": y0.shift(k) for k in range(1, max_lag+1)}\n",
        "    feats[\"roll_mean_7\"]  = y0.shift(1).rolling(7).mean()\n",
        "    feats[\"roll_mean_14\"] = y0.shift(1).rolling(14).mean()\n",
        "    feats[\"roll_mean_28\"] = y0.shift(1).rolling(28).mean()\n",
        "    feats[\"roll_med_7\"]   = y0.shift(1).rolling(7).median()\n",
        "    feats[\"roll_med_28\"]  = y0.shift(1).rolling(28).median()\n",
        "    feats[\"roll_std_7\"]   = y0.shift(1).rolling(7).std()\n",
        "    feats[\"roll_std_28\"]  = y0.shift(1).rolling(28).std()\n",
        "    return pd.DataFrame(feats, index=y.index)\n",
        "\n",
        "def smape_approx(y_true, y_pred, eps=1e-6):\n",
        "    yt = np.asarray(y_true); yp = np.asarray(y_pred)\n",
        "    mask = (yt != 0)\n",
        "    yt = yt[mask]; yp = yp[mask]\n",
        "    denom = (np.abs(yt) + np.abs(yp) + eps) / 2.0\n",
        "    return float(np.mean(np.abs(yp - yt) / denom)) if len(yt) else np.nan\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# 데이터 로드 & 전역(supervised) 테이블 (Recursive용)\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "def load_train(data_dir: Path) -> pd.DataFrame:\n",
        "    fp = data_dir / \"train\" / \"train.csv\"\n",
        "    df = pd.read_csv(fp)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "    df[\"영업일자\"] = pd.to_datetime(df[\"영업일자\"])\n",
        "    df[\"매출수량\"] = df[\"매출수량\"].astype(float).clip(lower=0)\n",
        "    sm = df[\"영업장명_메뉴명\"].astype(str).apply(split_store_menu)\n",
        "    df[\"업장명\"] = sm.apply(lambda x: x[0])\n",
        "    df[\"메뉴명\"] = sm.apply(lambda x: x[1])\n",
        "    return df\n",
        "\n",
        "def build_supervised_recursive(df: pd.DataFrame, max_lag=28, val_days=28):\n",
        "    rows = []; weights = []\n",
        "    for (store, menu), g in df.groupby([\"업장명\", \"메뉴명\"], sort=False):\n",
        "        g = g.sort_values(\"영업일자\")\n",
        "        full_idx = pd.date_range(g[\"영업일자\"].min(), g[\"영업일자\"].max(), freq=\"D\")\n",
        "        y = g.set_index(\"영업일자\")[\"매출수량\"].reindex(full_idx).fillna(0.0)\n",
        "        cal = build_calendar_features(pd.Series(full_idx, index=full_idx))\n",
        "        lags = make_lag_features(y, max_lag=max_lag)\n",
        "        feat = pd.concat([cal, lags], axis=1).iloc[max_lag:]\n",
        "        target = y.iloc[max_lag:]\n",
        "        feat[\"업장명\"] = store; feat[\"메뉴명\"] = menu; feat[\"target_date\"] = feat.index\n",
        "        sw = 2.0 if store in [\"담하\", \"미라시아\"] else 1.0\n",
        "        weights.extend([sw]*len(feat))\n",
        "        rows.append(pd.concat([feat, target.rename(\"y\")], axis=1))\n",
        "    data = pd.concat(rows, axis=0, ignore_index=True)\n",
        "    weights = pd.Series(weights, index=data.index, name=\"weight\")\n",
        "    cutoff = data[\"target_date\"].max() - pd.Timedelta(days=val_days)\n",
        "    train_mask = data[\"target_date\"] <= cutoff\n",
        "    val_mask   = data[\"target_date\"] >  cutoff\n",
        "    y_all = data[\"y\"]\n",
        "    X_all = data.drop(columns=[\"y\", \"target_date\"])\n",
        "    for cat in [\"업장명\", \"메뉴명\"]:\n",
        "        X_all[cat] = X_all[cat].astype(\"category\")\n",
        "    return (\n",
        "        X_all.loc[train_mask].reset_index(drop=True),\n",
        "        y_all.loc[train_mask].reset_index(drop=True),\n",
        "        X_all.loc[val_mask].reset_index(drop=True),\n",
        "        y_all.loc[val_mask].reset_index(drop=True),\n",
        "        weights.loc[train_mask].reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# Direct-H 학습 테이블: 앵커 t의 피처 → 타깃 y[t+h]\n",
        "# (훈련 시 피처는 날짜 t 기준 과거만 사용, 타깃은 t+h 로 shift)\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "def build_supervised_direct(df: pd.DataFrame, horizon: int, max_lag=28, val_days=28):\n",
        "    assert 1 <= horizon <= 7\n",
        "    rows = []; weights = []\n",
        "    for (store, menu), g in df.groupby([\"업장명\", \"메뉴명\"], sort=False):\n",
        "        g = g.sort_values(\"영업일자\")\n",
        "        full_idx = pd.date_range(g[\"영업일자\"].min(), g[\"영업일자\"].max(), freq=\"D\")\n",
        "        y = g.set_index(\"영업일자\")[\"매출수량\"].reindex(full_idx).fillna(0.0)\n",
        "\n",
        "        # 앵커 날짜 시퀀스\n",
        "        cal = build_calendar_features(pd.Series(full_idx, index=full_idx))\n",
        "        lags = make_lag_features(y, max_lag=max_lag)\n",
        "        feat = pd.concat([cal, lags], axis=1)\n",
        "\n",
        "        # 타깃은 y[t+h] → y.shift(-h)\n",
        "        target = y.shift(-horizon)\n",
        "\n",
        "        # 최대 랙 구간 이후 & 타깃 존재(t+h 범위 내)만 사용\n",
        "        valid_mask = pd.Series(True, index=feat.index)\n",
        "        valid_mask.iloc[:max_lag] = False           # 랙 버퍼\n",
        "        valid_mask.iloc[-horizon:] = False          # 타깃 존재 구간\n",
        "        feat = feat.loc[valid_mask]\n",
        "        targ = target.loc[valid_mask]\n",
        "\n",
        "        feat[\"업장명\"] = store; feat[\"메뉴명\"] = menu; feat[\"anchor_date\"] = feat.index\n",
        "        sw = 2.0 if store in [\"담하\", \"미라시아\"] else 1.0\n",
        "        weights.extend([sw]*len(feat))\n",
        "        rows.append(pd.concat([feat, targ.rename(\"y\")], axis=1))\n",
        "\n",
        "    data = pd.concat(rows, axis=0, ignore_index=True)\n",
        "    weights = pd.Series(weights, index=data.index, name=\"weight\")\n",
        "\n",
        "    cutoff = data[\"anchor_date\"].max() - pd.Timedelta(days=val_days + horizon - 1)\n",
        "    train_mask = data[\"anchor_date\"] <= cutoff\n",
        "    val_mask   = data[\"anchor_date\"] >  cutoff\n",
        "\n",
        "    y_all = data[\"y\"]\n",
        "    X_all = data.drop(columns=[\"y\", \"anchor_date\"])\n",
        "    for cat in [\"업장명\", \"메뉴명\"]:\n",
        "        X_all[cat] = X_all[cat].astype(\"category\")\n",
        "\n",
        "    return (\n",
        "        X_all.loc[train_mask].reset_index(drop=True),\n",
        "        y_all.loc[train_mask].reset_index(drop=True),\n",
        "        X_all.loc[val_mask].reset_index(drop=True),\n",
        "        y_all.loc[val_mask].reset_index(drop=True),\n",
        "        weights.loc[train_mask].reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# 학습기\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "def train_lgbm(X_train, y_train, X_val, y_val, w_train):\n",
        "    params = dict(\n",
        "        n_estimators=5000, learning_rate=0.03, subsample=0.9, colsample_bytree=0.9,\n",
        "        num_leaves=63, min_child_samples=40, random_state=SEED, objective=\"mae\",\n",
        "        reg_alpha=1e-3, reg_lambda=1e-3, verbose=-1\n",
        "    )\n",
        "    model = LGBMRegressor(**params)\n",
        "    model.fit(X_train, y_train, sample_weight=w_train, eval_set=[(X_val, y_val)], eval_metric=\"l1\", callbacks=[])\n",
        "    return model\n",
        "\n",
        "def train_recursive_model(df_train: pd.DataFrame):\n",
        "    X_tr, y_tr, X_va, y_va, w_tr = build_supervised_recursive(df_train, max_lag=28, val_days=28)\n",
        "    m = train_lgbm(X_tr, y_tr, X_va, y_va, w_tr)\n",
        "    val_pred = np.clip(m.predict(X_va), 0, None)\n",
        "    print(f\"[VAL][Recursive] SMAPE≈ {smape_approx(y_va.values, val_pred):.4f}\")\n",
        "    return m\n",
        "\n",
        "def train_direct_models(df_train: pd.DataFrame) -> Dict[int, LGBMRegressor]:\n",
        "    models = {}\n",
        "    for h in range(1, 8):\n",
        "        X_tr, y_tr, X_va, y_va, w_tr = build_supervised_direct(df_train, horizon=h, max_lag=28, val_days=28)\n",
        "        m = train_lgbm(X_tr, y_tr, X_va, y_va, w_tr)\n",
        "        val_pred = np.clip(m.predict(X_va), 0, None)\n",
        "        print(f\"[VAL][Direct h={h}] SMAPE≈ {smape_approx(y_va.values, val_pred):.4f}\")\n",
        "        models[h] = m\n",
        "    return models\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# 추론기 (Recursive/Direct/Naive)\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "def build_features_for_anchor(window: pd.Series, anchor_date: pd.Timestamp, store: str, menu: str) -> pd.DataFrame:\n",
        "    # 앵커일(=마지막 실제일 D) 기준 피처. Direct-H에서 사용.\n",
        "    cal = build_calendar_features(pd.Series([anchor_date]))\n",
        "    ldict = {f\"lag_{k}\": [window.iloc[-k] if len(window) >= k else 0.0] for k in range(1, 29)}\n",
        "    def roll(arr, w, fn):\n",
        "        s = pd.Series(arr)\n",
        "        return float(fn(s.iloc[-w:])) if len(arr) >= w else 0.0\n",
        "    vals = window.values\n",
        "    X = pd.concat([cal.reset_index(drop=True), pd.DataFrame({\n",
        "        \"roll_mean_7\":[roll(vals,7,np.mean)], \"roll_mean_14\":[roll(vals,14,np.mean)], \"roll_mean_28\":[roll(vals,28,np.mean)],\n",
        "        \"roll_med_7\":[roll(vals,7,np.median)], \"roll_med_28\":[roll(vals,28,np.median)],\n",
        "        \"roll_std_7\":[roll(vals,7,np.std)], \"roll_std_28\":[roll(vals,28,np.std)]\n",
        "    })], axis=1)\n",
        "    X[\"업장명\"] = pd.Series([store], dtype=\"category\")\n",
        "    X[\"메뉴명\"] = pd.Series([menu], dtype=\"category\")\n",
        "    return X.assign(**ldict)\n",
        "\n",
        "def predict_recursive_for_window(model: LGBMRegressor, last28: pd.Series, start_next: pd.Timestamp, store: str, menu: str) -> List[float]:\n",
        "    window = last28.clip(lower=0).copy()\n",
        "    preds = []\n",
        "    cur = start_next\n",
        "    for _ in range(7):\n",
        "        X = build_features_for_anchor(window, cur - pd.Timedelta(days=1), store, menu)  # anchor를 전날로 잡아도 동일 피처\n",
        "        yhat = float(model.predict(X)[0])\n",
        "        yhat = max(0.0, yhat)\n",
        "        preds.append(yhat)\n",
        "        window = pd.concat([window, pd.Series([yhat], index=[cur])])\n",
        "        cur += pd.Timedelta(days=1)\n",
        "    return preds\n",
        "\n",
        "def predict_direct_for_window(models_h: Dict[int, LGBMRegressor], last28: pd.Series, anchor_date: pd.Timestamp, store: str, menu: str) -> List[float]:\n",
        "    X_anchor = build_features_for_anchor(last28, anchor_date, store, menu)\n",
        "    out = []\n",
        "    for h in range(1, 8):\n",
        "        yhat = float(models_h[h].predict(X_anchor)[0])\n",
        "        out.append(max(0.0, yhat))\n",
        "    return out\n",
        "\n",
        "def naive_t7(last28: pd.Series) -> List[float]:\n",
        "    v = last28.values[-7:]\n",
        "    return [float(max(0.0, x)) for x in v]\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# 시계열 특성 계산 & 블렌딩 룰\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "def series_stats(last28: pd.Series) -> Dict[str, float]:\n",
        "    y = last28.clip(lower=0).values.astype(float)\n",
        "    s = float(np.sum(y))\n",
        "    zeros = float(np.mean(y == 0.0))\n",
        "    m = float(np.mean(y)) if len(y) else 0.0\n",
        "    sd = float(np.std(y)) if len(y) else 0.0\n",
        "    vol = (sd / m) if m > 0 else np.inf\n",
        "    # t vs t-7 상관 (겹치는 21개 비교)\n",
        "    if len(y) >= 28:\n",
        "        a = y[7:28]; b = y[0:21]\n",
        "        corr = float(np.corrcoef(a, b)[0,1]) if np.std(a)>0 and np.std(b)>0 else 0.0\n",
        "    else:\n",
        "        corr = 0.0\n",
        "    return {\"sum\": s, \"zero_ratio\": zeros, \"vol\": vol, \"corr7\": corr, \"mean\": m, \"std\": sd}\n",
        "\n",
        "def blend_rules(direct_7: List[float], recur_7: List[float], naive_7: List[float], stats: Dict[str, float]) -> List[float]:\n",
        "    # 기본 지평별 가중\n",
        "    base = []\n",
        "    for h in range(1, 8):\n",
        "        if h <= 2:   w_d, w_r = 0.4, 0.6\n",
        "        elif h <= 5: w_d, w_r = 0.6, 0.4\n",
        "        else:        w_d, w_r = 0.7, 0.3\n",
        "        base.append((w_d, w_r))\n",
        "    # 변동성↑ → Recursive 가중 +0.1 (최대 0.75)\n",
        "    if stats[\"vol\"] > 1.0:\n",
        "        base = [(wd, min(0.75, wr+0.1)) for (wd, wr) in base]\n",
        "        base = [(max(0.0, 1.0-wr), wr) for (_, wr) in base]  # 합=1 유지\n",
        "    # 혼합\n",
        "    blended = []\n",
        "    for h in range(7):\n",
        "        wd, wr = base[h]\n",
        "        v = wd*direct_7[h] + wr*recur_7[h]\n",
        "        blended.append(v)\n",
        "    # 희소/저판매 → 나이브 0.3 섞기\n",
        "    if (stats[\"sum\"] <= 5.0) or (stats[\"zero_ratio\"] >= 0.50):\n",
        "        blended = [0.7*b + 0.3*n for b, n in zip(blended, naive_7)]\n",
        "    # 음수 방지\n",
        "    return [max(0.0, float(x)) for x in blended]\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# 제출 포맷 안전 저장/검증\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "def write_out_submission(sample_path: Path, raw_out_df: pd.DataFrame, out_path: Path) -> None:\n",
        "    sample = pd.read_csv(sample_path)\n",
        "    sample.columns = [c.strip() for c in sample.columns]\n",
        "    key_col = sample.columns[0]\n",
        "    value_cols = list(sample.columns[1:])\n",
        "    aligned = sample[[key_col]].merge(raw_out_df, on=key_col, how=\"left\")\n",
        "    for c in value_cols:\n",
        "        if c in aligned.columns:\n",
        "            aligned[c] = pd.to_numeric(aligned[c], errors=\"coerce\").fillna(0.0).clip(lower=0.0)\n",
        "        else:\n",
        "            aligned[c] = 0.0\n",
        "    final = aligned[sample.columns]\n",
        "    assert list(final.columns) == list(sample.columns)\n",
        "    assert len(final) == len(sample)\n",
        "    assert final[key_col].equals(sample[key_col])\n",
        "    assert final[value_cols].isna().sum().sum() == 0\n",
        "    assert (final[value_cols].values < 0).sum() == 0\n",
        "    final.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "def validate_submission(submission_path: Path, sample_path: Path) -> None:\n",
        "    sub = pd.read_csv(submission_path)\n",
        "    samp = pd.read_csv(sample_path)\n",
        "    assert list(sub.columns) == list(samp.columns), \"열 이름/순서 불일치\"\n",
        "    assert len(sub) == len(samp), \"행 수 불일치\"\n",
        "    key = samp.columns[0]\n",
        "    assert sub[key].equals(samp[key]), \"'영업일자' 키 순서 불일치\"\n",
        "    vals = samp.columns[1:]\n",
        "    assert sub[vals].isna().sum().sum() == 0, \"값 열에 NaN 존재\"\n",
        "    assert (sub[vals].values < 0).sum() == 0, \"값 열에 음수 존재\"\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# 최종 빌드: Direct+Recursive+Naive 블렌딩\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "def train_and_predict_blend(data_dir: str, out_csv: str = \"submission.csv\"):\n",
        "    data_dir = Path(data_dir)\n",
        "    assert (data_dir / \"train\" / \"train.csv\").exists(), \"train/train.csv not found\"\n",
        "    assert (data_dir / \"sample_submission.csv\").exists(), \"sample_submission.csv not found\"\n",
        "\n",
        "    print(\"[1/4] Load train\")\n",
        "    train_df = load_train(data_dir)\n",
        "\n",
        "    print(\"[2/4] Train models: Recursive + Direct-H(1..7)\")\n",
        "    rec_model = train_recursive_model(train_df)\n",
        "    dir_models = train_direct_models(train_df)\n",
        "\n",
        "    print(\"[3/4] Inference per TEST_xx with blending rules\")\n",
        "    sample_path = data_dir / \"sample_submission.csv\"\n",
        "    sample = pd.read_csv(sample_path)\n",
        "    sample.columns = [c.strip() for c in sample.columns]\n",
        "    menu_cols = list(sample.columns[1:])\n",
        "\n",
        "    # (test_id, 메뉴명) -> 7개 예측 보관\n",
        "    pred_cache: Dict[Tuple[str, str], List[float]] = {}\n",
        "\n",
        "    for i in range(10):\n",
        "        test_id = f\"TEST_{i:02d}\"\n",
        "        fp = data_dir / \"test\" / f\"{test_id}.csv\"\n",
        "        if not fp.exists():\n",
        "            raise FileNotFoundError(f\"Missing: {fp}\")\n",
        "        tdf = pd.read_csv(fp)\n",
        "        tdf[\"영업일자\"] = pd.to_datetime(tdf[\"영업일자\"])\n",
        "\n"
      ],
      "id": "32LR50BV49m_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfWmWZb649nA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6a07e0-c38a-4c08-b903-bcb61e4ba1f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/4] Load train\n",
            "[2/4] Train models: Recursive + Direct-H(1..7)\n",
            "[VAL][Recursive] SMAPE≈ 0.7953\n",
            "[VAL][Direct h=1] SMAPE≈ 0.8078\n",
            "[VAL][Direct h=2] SMAPE≈ 0.7984\n",
            "[VAL][Direct h=3] SMAPE≈ 0.8010\n"
          ]
        }
      ],
      "source": [
        "# 실행 예시\n",
        "data_dir = './data'  # 데이터 위치로 변경\n",
        "out_csv  = 'submission.csv'\n",
        "train_and_predict_blend(data_dir=\"./data\", out_csv=\"submission.csv\")\n",
        "\n",
        "print('노트북 준비 완료. data_dir를 지정해 실행하세요.')\n"
      ],
      "id": "XfWmWZb649nA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "203e3a9d",
        "outputId": "1081288f-9da2-49cb-f635-391e319d3090"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the new directory structure\n",
        "new_data_dir = '/content/data'\n",
        "new_train_dir = os.path.join(new_data_dir, 'train')\n",
        "new_test_dir = os.path.join(new_data_dir, 'test')\n",
        "\n",
        "# Create the new directories if they don't exist\n",
        "os.makedirs(new_train_dir, exist_ok=True)\n",
        "os.makedirs(new_test_dir, exist_ok=True)\n",
        "\n",
        "# Move the files\n",
        "files_to_move = {\n",
        "    '/content/train.csv': new_train_dir,\n",
        "    '/content/sample_submission.csv': new_data_dir,\n",
        "}\n",
        "\n",
        "for i in range(10):\n",
        "    test_file = f'/content/TEST_{i:02d}.csv'\n",
        "    if os.path.exists(test_file):\n",
        "        files_to_move[test_file] = new_test_dir\n",
        "\n",
        "for src, dest_dir in files_to_move.items():\n",
        "    if os.path.exists(src):\n",
        "        shutil.move(src, dest_dir)\n",
        "        print(f\"Moved {src} to {dest_dir}\")\n",
        "    else:\n",
        "        print(f\"Warning: {src} not found.\")"
      ],
      "id": "203e3a9d",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moved /content/train.csv to /content/data/train\n",
            "Warning: /content/sample_submission.csv not found.\n",
            "Moved /content/TEST_00.csv to /content/data/test\n",
            "Moved /content/TEST_01.csv to /content/data/test\n",
            "Moved /content/TEST_02.csv to /content/data/test\n",
            "Moved /content/TEST_03.csv to /content/data/test\n",
            "Moved /content/TEST_04.csv to /content/data/test\n",
            "Moved /content/TEST_05.csv to /content/data/test\n",
            "Moved /content/TEST_06.csv to /content/data/test\n",
            "Moved /content/TEST_07.csv to /content/data/test\n",
            "Moved /content/TEST_08.csv to /content/data/test\n",
            "Moved /content/TEST_09.csv to /content/data/test\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}